from datetime import datetime, timedelta
from airflow import DAG
from airflow.providers.apache.kafka.operators.consume import ConsumeFromTopicOperator
import json
import logging

default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': datetime(2023, 1, 1),
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

def process_message(message):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–∑ Kafka."""
    logger = logging.getLogger(__name__)
    
    try:
        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –∫–ª—é—á –∏ –∑–Ω–∞—á–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        message_key = message.key().decode('utf-8') if message.key() else None
        message_value = message.value().decode('utf-8')
        event_data = json.loads(message_value)
        
        logger.info(f"üì• –ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ. –ö–ª—é—á: {message_key}, –î–∞–Ω–Ω—ã–µ: {event_data}")
        
        # –ë–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Å–æ–±—ã—Ç–∏–π
        if event_data['event_type'] == 'user_registration':
            logger.info(f"–ù–æ–≤—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {event_data['user_id']} —Å —Ç–∞—Ä–∏—Ñ–æ–º {event_data['data']['plan']}")
        elif event_data['event_type'] == 'purchase':
            logger.info(f"–ü–æ–∫—É–ø–∫–∞ –æ—Ç {event_data['user_id']}: –ø—Ä–æ–¥—É–∫—Ç {event_data['data']['product_id']}, —Å—É–º–º–∞ {event_data['data']['amount']}")
        
        return event_data
        
    except Exception as e:
        logger.error(f"!!! –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
        return None

with DAG(
    'kafka_consumer_dag',
    default_args=default_args,
    description='DAG –¥–ª—è —á—Ç–µ–Ω–∏—è –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ Kafka',
    schedule_interval=timedelta(minutes=35),
    catchup=False,
    tags=['kafka', 'consumer'],
) as dag:

    consume_task = ConsumeFromTopicOperator(
        task_id='consume_from_user_events',
        kafka_config_id='kafka_default',
        topics=['user_events'],
        apply_function=process_message,
        commit_cadence='end_of_batch',
        max_messages=5,
        max_batch_size=5,
    )