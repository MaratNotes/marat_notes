# Практика: SparkSession и настройка партиций

> Почему дефолтные 200 партиций убивают производительность на маленьких данных?  
> Демо: 8 партиций vs 2000 партиций — разница в скорости ×2.5–3×.

[Telegram](https://t.me/marat_notes)
[Youtube](https://youtu.be/RqWQpgwQuWE)
[Vk](https://vkvideo.ru/video-231048746_456239043)

---

## Цель практики

- Понять разницу между партициями чтения и шаффла
- Научиться подбирать оптимальное число партиций под объём данных и железо
- Увидеть работу адаптивного режима (AQE) в действии

---

## Требования

- Docker
- 2 ГБ свободной памяти
- Доступ к порту 8888
## Как запустить

1. Создайте папку проекта, например:  
   `D:\projects\pyspark-docker`

2. Откройте **PowerShell в этой папке**:  
   - В проводнике: **Shift + ПКМ** → «Открыть окно PowerShell здесь»

3. Выполните команду:
   ```powershell
   docker run -p 8888:8888 --name pyspark-jupyter -v ${PWD}:/home/jovyan/work jupyter/pyspark-notebook
   ```

4. Скопируйте ссылку с токеном из терминала и откройте в браузере.


## Структура_прроекта
19_spark_session/
├── README.md                # этот файл


├── SparkSessionExample.ipynb               # ноутбук с демо (генерация + 3 теста)


└── retail.csv/              # сгенерированные данные (появится после запуска)


└── Apache_Spark-SparkSession.pdf  # презентация по заданной теме
